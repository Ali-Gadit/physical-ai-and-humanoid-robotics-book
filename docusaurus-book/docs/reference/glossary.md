---
id: glossary
title: "Glossary of Terms"
sidebar_position: 1
---

# Glossary of Terms

## A

**Actuator** - A component of a robot that converts energy (usually electrical) into mechanical motion. Common actuators include servo motors, stepper motors, and hydraulic cylinders.

**Artificial Intelligence (AI)** - The simulation of human intelligence processes by machines, especially computer systems. Specific applications in robotics include learning, reasoning, problem-solving, perception, and language understanding.

**Autonomous System** - A system that operates independently without direct human control, making decisions based on sensor input and pre-programmed behaviors.

## B

**Balance Control** - The ability of a robot to maintain its center of mass within its support polygon to avoid falling. Critical for humanoid robots with bipedal locomotion.

**Behavior Tree** - A hierarchical structure used in robotics and game AI to organize and execute complex behaviors. It provides a flexible way to create sophisticated robot behaviors.

**Bipedal Locomotion** - The ability to walk on two legs, which is a key challenge in humanoid robotics due to the inherent instability of the two-legged configuration.

**Bounding Box** - A rectangular box that encloses an object in 2D or 3D space, commonly used in computer vision and object detection.

## C

**Center of Mass (CoM)** - The point in a robot where its mass is equally distributed in all directions. Critical for balance and stability in humanoid robots.

**Computer Vision** - A field of artificial intelligence that trains computers to interpret and understand the visual world. Uses digital images, video, and machine learning to identify and classify objects.

**Control Theory** - A field of engineering and mathematics that deals with the behavior of dynamical systems with inputs, and how their behavior is modified by feedback.

**Cognitive Planning** - The process of using AI to decompose high-level goals into executable action sequences, often using large language models to interpret natural language commands.

## D

**Deep Learning** - A subset of machine learning that uses artificial neural networks with multiple layers to model and understand complex patterns in data.

**Digital Twin** - A virtual representation of a physical system that simulates its behavior and characteristics. Used extensively in robotics for testing and validation.

**Domain Randomization** - A technique in simulation where environment parameters (textures, lighting, physics properties) are randomly varied to improve Sim-to-Real transfer of AI models.

**Dynamixel** - A brand of smart servomotors commonly used in humanoid robotics for precise control of joint positions and torques.

## E

**Embodied AI** - Artificial intelligence that is integrated with a physical body that can interact with the real world. The physical embodiment is considered essential for true intelligence.

**End Effector** - The device at the end of a robot arm designed to interact with the environment. For humanoid robots, this typically refers to the hand.

**Episodic Memory** - A type of memory system that stores specific events and experiences, important for robots that need to remember past interactions.

**Ethical AI** - The development and implementation of artificial intelligence systems that are fair, transparent, accountable, and respect human rights and values.

## F

**Forward Kinematics** - The process of determining the position and orientation of the end effector based on the joint angles of a robot.

**Force Control** - A control strategy that regulates the forces applied by a robot rather than just its position, important for safe human-robot interaction.

**Friction Cone** - A mathematical model used to represent the limits of frictional forces that can be applied at a contact point, important for robot stability.

**Fused Reality** - A concept combining virtual and physical realities to create seamless human-robot interaction experiences.

## G

**Gazebo** - A 3D simulation environment that provides physics simulation, realistic rendering, and sensor simulation capabilities for robotics applications.

**Generalized Coordinates** - A set of parameters that define the configuration of a mechanical system, such as joint angles in a robot.

**GPU Acceleration** - The use of Graphics Processing Units to accelerate computation, especially important for AI inference and computer vision in robotics.

**Gripper** - A device mounted on a robot arm that enables it to grasp and hold objects.

## H

**Hardware-in-the-Loop (HIL)** - A testing methodology that involves running a simulation with real hardware components connected to the simulation.

**Homing Procedure** - The process by which a robot determines its absolute position by moving to known reference points.

**Human-Robot Interaction (HRI)** - The study of interactions between humans and robots, focusing on design and implementation of robots for human use.

**Humanoid Robot** - A robot with a physical structure that resembles the human body, typically with a head, torso, two arms, and two legs.

## I

**Inertial Measurement Unit (IMU)** - A device that measures and reports a body's specific force, angular rate, and sometimes the magnetic field surrounding the body, using accelerometers, gyroscopes, and magnetometers.

**Inverse Kinematics** - The process of determining the joint angles required to achieve a desired position and orientation of the end effector.

**Isaac Sim** - NVIDIA's robotics simulation application based on the NVIDIA Omniverse platform, providing photorealistic simulation and synthetic data generation.

**Isaac ROS** - NVIDIA's hardware-accelerated perception and navigation packages that bridge the gap between ROS 2 and NVIDIA's GPU computing platform.

**Iteration Space** - A concept in robotics development referring to the range of possible design iterations and testing scenarios.

## J

**Joint Space** - The space defined by the joint angles of a robot, as opposed to Cartesian space which is defined by position coordinates.

**Joint Trajectory Controller** - A ROS 2 controller that allows for precise control of joint positions, velocities, and accelerations over time.

## K

**Kinematics** - The study of motion without considering the forces that cause it. In robotics, it deals with the relationship between joint positions and end-effector positions.

**Kinesthetic Teaching** - A method of teaching robot movements by physically guiding the robot through the desired motion.

**Kubernetes** - An open-source container orchestration platform that can be used to manage distributed robotics systems.

## L

**LIDAR** - Light Detection and Ranging, a remote sensing method that uses light in the form of a pulsed laser to measure distances.

**Large Language Model (LLM)** - Advanced AI models capable of understanding and generating human-like text, increasingly used for cognitive planning in robotics.

**Legislation for Robotics** - Legal frameworks governing the use and development of robotics technology, including liability and safety standards.

**Liability in Robotics** - Legal responsibility for damages caused by robotic systems, an emerging field as robots become more autonomous.

**Linux** - The operating system of choice for most robotics applications due to its real-time capabilities and open-source nature.

**Localization** - The process of determining a robot's position and orientation within a known map of its environment.

## M

**Machine Learning** - A method of training algorithms to learn from and make predictions or decisions based on data, without being explicitly programmed for each task.

**Manipulation** - The ability of a robot to physically interact with objects in its environment, typically using end effectors.

**Manipulator** - A robotic device designed to manipulate objects in its environment, typically consisting of a series of joints and links.

**Marker Detection** - The process of identifying and tracking specific visual markers in a robot's environment for navigation and localization.

**Middleware** - Software that provides common services and capabilities to applications beyond what's offered by the operating system, such as ROS 2.

**Modular Design** - An approach to system design that separates functionality into independent, interchangeable modules.

**Monte Carlo Method** - A computational technique that uses random sampling to obtain numerical results, often used in robotics for uncertainty propagation.

## N

**Navigation** - The process by which a robot determines and follows a path from one location to another.

**Nav2** - The ROS 2 navigation stack that provides path planning, obstacle avoidance, and localization capabilities.

**Neural Network** - A series of algorithms that endeavors to recognize underlying relationships in a set of data through a process that mimics how the human brain operates.

**Newton-Euler Algorithm** - A method for computing the inverse dynamics of a robot, determining the forces and torques required to achieve a given motion.

**NVIDIA Isaac** - NVIDIA's comprehensive robotics platform that includes simulation, perception, and control tools optimized for GPU acceleration.

## O

**Occupancy Grid** - A probabilistic representation of an environment used in robotics for navigation and path planning, dividing space into discrete cells that are either occupied or free.

**Odometry** - The use of data from motion sensors to estimate change in position over time, commonly used for robot localization.

**Operational Space Control** - A control approach that operates in the task space (Cartesian space) rather than joint space, allowing for direct control of end-effector behavior.

**Omniverse** - NVIDIA's simulation and collaboration platform that enables real-time 3D design workflows and virtual worlds.

## P

**Path Planning** - The computational problem of finding a valid sequence of configurations to move from a start to a goal state while avoiding obstacles.

**Perception Pipeline** - The sequence of processing steps that convert raw sensor data into meaningful information about the environment.

**Physical AI** - AI systems that function in the physical world and comprehend physical laws, as opposed to traditional AI systems confined to digital environments.

**PID Controller** - A control loop feedback mechanism widely used in robotics and industrial control systems, using Proportional, Integral, and Derivative terms.

**Point Cloud** - A collection of data points in space, typically representing the external surface of an object, used in 3D mapping and perception.

**Proportional-Integral-Derivative (PID) Control** - A control algorithm that uses a weighted sum of proportional, integral, and derivative terms to minimize error in control systems.

## Q

**Quaternion** - A mathematical construct used to represent rotations in 3D space, preferred over Euler angles for avoiding gimbal lock.

**Quality of Service (QoS)** - In ROS 2, QoS policies allow for fine-tuning of communication behavior between publishers and subscribers, including reliability and durability settings.

## R

**Real-Time Operating System (RTOS)** - An operating system intended to serve real-time applications that process data as it comes in, typically without buffer delays.

**Reality Capture** - The process of digitally capturing aspects of the real world using sensors and cameras to create virtual representations.

**Reinforcement Learning** - A type of machine learning where an agent learns to make decisions by performing actions and receiving rewards or penalties.

**Robot Operating System 2 (ROS 2)** - The next generation of ROS, designed for production environments with improved security, real-time capabilities, and multi-robot systems.

**ROS Bridge** - Software components that enable communication between ROS/ROS 2 and other systems, such as web browsers or simulation environments.

**ROS Control** - The standard framework for controlling robot hardware in ROS, providing interfaces for joint control and hardware abstraction.

**ROS Domain** - A communication domain in ROS 2 that isolates different ROS 2 systems running on the same network.

**Runtime Verification** - Techniques for monitoring and verifying the behavior of systems during execution to ensure they meet specified requirements.

## S

**Safety-Critical System** - A system whose failure or malfunction could result in loss of life, significant property damage, or environmental damage.

**Sensor Fusion** - The process of combining sensory data from multiple sources to achieve better accuracy and reliability than could be achieved by using a single sensor alone.

**Sim-to-Real Transfer** - The process of transferring behaviors learned in simulation to real-world robotic systems, a key challenge in robotics.

**SLAM (Simultaneous Localization and Mapping)** - The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it.

**Social Robot** - A robot designed to interact with humans in a socially acceptable manner, often featuring humanoid characteristics.

**State Estimation** - The process of estimating the internal state of a system from noisy and incomplete observations.

**System Integration** - The process of bringing together different components of a robotic system to function as a unified whole.

## T

**Teleoperation** - The remote operation of a robot by a human operator, often used for tasks that require human judgment but are dangerous or difficult to perform directly.

**Temporal Logic** - A formal system for reasoning about propositions qualified in terms of time, used in robotics for specifying complex behaviors.

**Thermal Management** - The process of managing heat generation and dissipation in robotic systems to maintain safe operating temperatures.

**Torque Control** - A control strategy that directly controls the torque applied by robot joints, important for compliant and safe interaction.

**Trajectory Planning** - The process of creating a time-parameterized path that specifies the desired position, velocity, and acceleration of robot joints or end-effectors over time.

## U

**Ubuntu** - A popular Linux distribution that serves as the standard operating system for most ROS-based robotics development.

**Unified Robot Description Format (URDF)** - An XML format for representing robot models in ROS, describing kinematics, dynamics, visual, and collision properties.

**Unity** - A popular game engine used for creating high-fidelity simulation environments and human-robot interaction interfaces.

**Unstructured Environment** - An environment without predetermined organization or layout, challenging for robot navigation and manipulation.

## V

**Variable Impedance Control** - A control approach that allows robots to adjust their mechanical impedance (resistance to motion) based on task requirements.

**Vision-Language-Action (VLA)** - Systems that integrate visual perception, language understanding, and physical action for natural human-robot interaction.

**Visual Servoing** - The control of a robot using visual feedback, where camera images are used to guide robot motion.

**VSLAM (Visual SLAM)** - SLAM using visual sensors (cameras) as the primary input for localization and mapping.

## W

**Whole-Body Control** - A control approach that considers the entire robot body when generating control commands, optimizing for multiple simultaneous objectives.

**Wrench** - A mathematical representation combining forces and torques acting on a body, used in robot manipulation and control.

**Workspace** - The space within which a robot can position its end effector, determined by the robot's kinematic structure.

## X

**Xacro** - An XML macro language for generating URDF files, allowing for parameterization and reuse of robot model components.

## Y

**Yaw** - The rotation of a robot around its vertical (z) axis, typically describing turning motion.

## Z

**Zero Moment Point (ZMP)** - A concept used in bipedal locomotion to characterize the dynamic stability of walking robots, representing the point where the moment of the ground reaction force is zero.

**ZMP Control** - A control strategy for bipedal robots that maintains the Zero Moment Point within the support polygon to ensure stable walking.

---

### Acronyms and Abbreviations

- **AI**: Artificial Intelligence
- **API**: Application Programming Interface
- **CPU**: Central Processing Unit
- **GPU**: Graphics Processing Unit
- **HRI**: Human-Robot Interaction
- **IMU**: Inertial Measurement Unit
- **IoT**: Internet of Things
- **IP**: Intellectual Property
- **LAN**: Local Area Network
- **LED**: Light Emitting Diode
- **LLM**: Large Language Model
- **LIDAR**: Light Detection and Ranging
- **NLP**: Natural Language Processing
- **OD**: Object Detection
- **PID**: Proportional-Integral-Derivative
- **QoS**: Quality of Service
- **ROS**: Robot Operating System
- **ROS 2**: Robot Operating System 2
- **RT**: Real-Time
- **SLAM**: Simultaneous Localization and Mapping
- **TCP/IP**: Transmission Control Protocol/Internet Protocol
- **UI**: User Interface
- **URDF**: Unified Robot Description Format
- **USB**: Universal Serial Bus
- **VLA**: Vision-Language-Action
- **VSLAM**: Visual SLAM
- **WiFi**: Wireless Fidelity
- **XML**: eXtensible Markup Language
- **YAML**: YAML Ain't Markup Language
- **ZMP**: Zero Moment Point

---

This glossary provides definitions for key terms used throughout the Physical AI & Humanoid Robotics course. As the field evolves, new terms will be added and existing definitions refined to reflect current best practices and technological developments.